{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d70d4-2f9a-4f8b-90ac-23e785ba07a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "print(sd.query_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383cd7e-3d43-451f-8407-ee7b6280ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speak into one mic only this will help identify which mic is which\n",
    "#LEFT MIC HAS WHITE DOT\n",
    "#VERIFY MIC IDECIES\n",
    "\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "fs = 44100  # Sample rate\n",
    "chunk = 1024\n",
    "seconds = 2  # Short test recording\n",
    "\n",
    "for mic_index in [1, 2]:  # Replace with actual device indices\n",
    "    print(f\"Testing Microphone {mic_index}. Speak into it now...\")\n",
    "    \n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=fs, input=True, input_device_index=mic_index, frames_per_buffer=chunk)\n",
    "    \n",
    "    frames = []\n",
    "    for _ in range(0, int(fs / chunk * seconds)):\n",
    "        data = stream.read(chunk, exception_on_overflow=False)\n",
    "        frames.append(np.frombuffer(data, dtype=np.int16))\n",
    "    \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # Convert to numpy array and print summary\n",
    "    audio_data = np.concatenate(frames)\n",
    "    print(f\"Microphone {mic_index} Average Amplitude: {np.mean(np.abs(audio_data))}\\n\")\n",
    "\n",
    "p.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb683744-813f-47c2-9d3d-38d522384aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record sound clip from both mics at the same time\n",
    "\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Replace these with the correct indices you found\n",
    "LEFT_MIC_INDEX = 1\n",
    "RIGHT_MIC_INDEX = 2\n",
    "\n",
    "DURATION = 1.0  # seconds\n",
    "SAMPLERATE = 44100\n",
    "\n",
    "# Buffer to hold both mic recordings\n",
    "recordings = {}\n",
    "\n",
    "# Record from both devices using threads\n",
    "def record_from_device(index, key):\n",
    "    recording = sd.rec(int(DURATION * SAMPLERATE), samplerate=SAMPLERATE, channels=1, device=index, dtype='float32')\n",
    "    sd.wait()\n",
    "    recordings[key] = recording.flatten()\n",
    "\n",
    "# Start both recordings nearly simultaneously\n",
    "from threading import Thread\n",
    "\n",
    "t1 = Thread(target=record_from_device, args=(LEFT_MIC_INDEX, 'left'))\n",
    "t2 = Thread(target=record_from_device, args=(RIGHT_MIC_INDEX, 'right'))\n",
    "\n",
    "start_time = time.time()\n",
    "t1.start(); t2.start()\n",
    "t1.join(); t2.join()\n",
    "print(f\"Recording finished. Elapsed: {time.time() - start_time:.3f}s\")\n",
    "\n",
    "# Save to .wav files\n",
    "sf.write('mic_left.wav', recordings['left'], SAMPLERATE)\n",
    "sf.write('mic_right.wav', recordings['right'], SAMPLERATE)\n",
    "print(\"Saved mic_left.wav and mic_right.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7653b-0e91-4bf8-b498-009446a58c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine correction factor\n",
    "#To do so clap directly between the mics then run this chunk of code\n",
    "#Manually add correlation factor into the rest of the code (this way it wont needed to be changed every time you run the code)\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy.signal import correlate\n",
    "\n",
    "# Load recordings\n",
    "left, sr = sf.read('mic_left.wav')\n",
    "right, _ = sf.read('mic_right.wav')\n",
    "\n",
    "# Ensure same length\n",
    "min_len = min(len(left), len(right))\n",
    "left = left[:min_len]\n",
    "right = right[:min_len]\n",
    "\n",
    "# Normalize both signals\n",
    "left = (left - np.mean(left)) / np.std(left)\n",
    "right = (right - np.mean(right)) / np.std(right)\n",
    "\n",
    "# Cross-correlation to estimate delay\n",
    "corr = correlate(left, right, mode='full')\n",
    "lags = np.arange(-len(left) + 1, len(right))\n",
    "offset = lags[np.argmax(corr)]\n",
    "\n",
    "# Print the correction factor\n",
    "print(f\"Estimated correction factor (manual_offset_samples) = {offset} samples\")\n",
    "\n",
    "#postive value means left lags behind right\n",
    "#Negative value means right lags behind left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771c184-f391-4e91-b0c7-53c46eed044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyaudio\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# Audio parameters\n",
    "fs = 44100\n",
    "chunk = 1024\n",
    "record_seconds = 1\n",
    "\n",
    "# Manual timing correction\n",
    "manual_offset_samples = 276  # Adjust this based on your setup\n",
    "\n",
    "# Speed of sound and mic spacing\n",
    "speed_of_sound = 343.0\n",
    "mic_distance = 0.37465  # Distance between microphones in meters\n",
    "\n",
    "# Your actual device indices (update these as needed)\n",
    "mic_indices = [1, 2]\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "streams = []\n",
    "for idx in mic_indices:\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=1,\n",
    "                    rate=fs,\n",
    "                    input=True,\n",
    "                    input_device_index=idx,\n",
    "                    frames_per_buffer=chunk)\n",
    "    streams.append(stream)\n",
    "\n",
    "# Control flag\n",
    "keep_running = True\n",
    "\n",
    "def localization_loop():\n",
    "    global keep_running\n",
    "    while keep_running:\n",
    "        print(\"Recording...\")\n",
    "        data = {i: [] for i in mic_indices}\n",
    "        for _ in range(0, int(fs / chunk * record_seconds)):\n",
    "            for i, stream in zip(mic_indices, streams):\n",
    "                audio_chunk = stream.read(chunk, exception_on_overflow=False)\n",
    "                data[i].append(np.frombuffer(audio_chunk, dtype=np.int16))\n",
    "\n",
    "        left = np.concatenate(data[mic_indices[1]])\n",
    "        right = np.concatenate(data[mic_indices[0]])\n",
    "\n",
    "        # Apply correction\n",
    "        if manual_offset_samples > 0:\n",
    "            left_corr = left[manual_offset_samples:]\n",
    "            right_corr = right[:len(left_corr)]\n",
    "        elif manual_offset_samples < 0:\n",
    "            right_corr = right[-manual_offset_samples:]\n",
    "            left_corr = left[:len(right_corr)]\n",
    "        else:\n",
    "            left_corr = left\n",
    "            right_corr = right\n",
    "\n",
    "        min_len = min(len(left_corr), len(right_corr))\n",
    "        left_corr = left_corr[:min_len]\n",
    "        right_corr = right_corr[:min_len]\n",
    "\n",
    "        # Peaks\n",
    "        left_peak = np.argmax(np.abs(left_corr))\n",
    "        right_peak = np.argmax(np.abs(right_corr))\n",
    "\n",
    "        peak_diff_samples = left_peak - right_peak\n",
    "        time_diff = peak_diff_samples / fs\n",
    "        distance_diff = speed_of_sound * time_diff\n",
    "\n",
    "        closer = \"Right Mic\" if distance_diff > 0 else \"Left Mic\"\n",
    "\n",
    "        # Plot\n",
    "        x = np.arange(min_len)\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.plot(x, left_corr, label='Left Mic', alpha=0.5, color='blue')\n",
    "        plt.plot(x, right_corr, label='Right Mic', alpha=0.5, color='red')\n",
    "        plt.scatter(left_peak, left_corr[left_peak], color='cyan', label=f\"Left Peak ({left_peak})\")\n",
    "        plt.scatter(right_peak, right_corr[right_peak], color='orange', label=f\"Right Peak ({right_peak})\")\n",
    "        plt.title(f\"{closer} is closer | Î” Distance: {abs(distance_diff):.4f} m\")\n",
    "        plt.xlabel(\"Sample Index\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(\"Localization loop ended.\")\n",
    "\n",
    "# Start the loop in a thread\n",
    "localization_thread = threading.Thread(target=localization_loop)\n",
    "localization_thread.start()\n",
    "\n",
    "# Stop function you can call manually\n",
    "def stop():\n",
    "    global keep_running\n",
    "    keep_running = False\n",
    "    localization_thread.join()\n",
    "    for stream in streams:\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "    p.terminate()\n",
    "    print(\"All audio streams closed and thread stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3a44f-0634-4047-8eaf-814f897a9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
